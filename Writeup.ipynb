{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection\n",
    "[![Udacity - Self-Driving Car NanoDegree](https://s3.amazonaws.com/udacity-sdc/github/shield-carnd.svg)](http://www.udacity.com/drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Normalize the features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run the pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Rubric](https://review.udacity.com/#!/rubrics/513/view) Points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Pipeline Description\n",
    "The Vehicle Detection pipeline is described in this section:\n",
    "* A Feature_extractor class is defined which can extract the features as per configuration provided in an input image. An instance of this class is used everywhere in the pipeline as well as during testing and visualization to maintain consistency.\n",
    "* A Car_Finder class is used to do the following\n",
    "    * Create Multi Scale Windows\n",
    "    * Search for cars in the input image using the multi scale windows\n",
    "    * Create the prediction vector and heatmap using search output\n",
    "    * Create the Labels and labeled bounding boxes\n",
    "    * Returning the Annotated image\n",
    "    \n",
    "* A LinearSVC from sklearn has been used. The tuning table of the C parameter is provided in later sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Training Data\n",
    "The standard training data provided in the project materials has been used to train the Classifier mentioned in the pipeline. Examples of Car and non Car images are shown below.\n",
    "![Cars and Non Cars](./writeup_helpers/Training_Data.png \"Examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Feature Exploration\n",
    "A Class called Feature_extractor was defined which is capable of extracting Spatial, Histogram as well as Hog features for an input image. This class is configured for various different features and the Concatenated feature output was plotted for visualization. Examples of such plots are provided below\n",
    "\n",
    "![Spatial](./writeup_helpers/Spatial.png \"Spatial\")\n",
    "![Histogram](./writeup_helpers/Hist.png \"Histogram\")\n",
    "![Hog](./writeup_helpers/Hog.png \"Hog\")\n",
    "![Concatenated](./writeup_helpers/Concatenated.png \"Concatenated\")\n",
    "\n",
    "Various combinations were tried and the observations are enumerated below:\n",
    "* Histogram features were consistently similar for Car and Non Car Images\n",
    "* Spatial Features' plots increased in similarity on increase in spatial_size parameter\n",
    "* HOG Yielded best results in YUV colorspace with 11 Orientation bins\n",
    "* Combination of Spatial and HOG features resulted in a superior classifier to using pure HOG features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Classifier Training\n",
    "\n",
    "A Linear SVC was used to train over the entire set of Normalized Features for cars and non cars. Data was split using sklearn into training and validation sets. The C parameter was tuned empirically\n",
    "Accuracy observations are Enumerated below\n",
    "* ||Features: Spatial + Hog||\n",
    "* Classifier: LinearSVC\n",
    "* C:default, Accuracy: 95.67\n",
    "* C:0.1, Accuracy: 96.6\n",
    "* C:0.01, Accuracy: 97.05\n",
    "* C:0.001, Accuracy: 97.94 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Finding Cars\n",
    "A Class called Car_finder has been defined in code. Objects of the feature extractor used to train and the X scaler and the trained classifier are passed to the Car finder class as arguments upon instantiation. \n",
    "\n",
    "#### 5.1 Creating multi scale windows for searching\n",
    "This class creates various multi scale windows and initializes its own windows attribute. This attributes value will be used to search for incoming frames.\n",
    "Examples of search windows are provided below\n",
    "\n",
    "![Windows_1](./writeup_helpers/search_windows1.png \"192\")\n",
    "![Windows 2](./writeup_helpers/search_windows2.png \"128\")\n",
    "![Windows 3](./writeup_helpers/search_windows3.png \"64\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Searching for Cars\n",
    "Iterating through the windows attribute initialized in the previous step, the input image was cropped by search window, resized to 64x64. The feature extractor was used to extract the features and pass it on to the trained classifier. The predictions were concatenated into a 1D array and returned. The find_raw function in the class source code is responsible for this. The windows with the respective indices that return positive values are used to find the detection vertices.\n",
    "![Raw](./writeup_helpers/raw.png \"Raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Creating and thresholding the Heatmap\n",
    "The Heatmap was created by incrementing all the pixel values in positive detection windows.\n",
    "![Heatmap](./writeup_helpers/heatmap.png \"Heatmap\")\n",
    "Threshold was empirically tuned to a value of 2 to remove false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Extracting the final bounding boxes\n",
    "The label function was used to extract the final bounding boxes on the image.\n",
    "![Final](./writeup_helpers/final.png \"Final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Processing Video Frames\n",
    "Since I used a class based approach for My Software elements, Deploying the pipeline for video detection was quite simple. The video is provided as project_video_out.avi in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Discussion\n",
    "* Since I used a class based approach for Code reusability, I was unable to integrate the performance optimizations as discussed in the Lesson materials. For Feature extractions, I pretty much wrapped the functions provided in the lesson_functions.py file provided in the study materials into my code. I do want to improve performance by implementing the hog feature finding optimizations into my class. I also want to use multiple threads to process several multiscale windows simultaneously.\n",
    "* Since the detection pipeline is dependent on Spatial and Hog Features, the Differnce between the background and the Vehicle region plays a key role in true or false detections. I would like to include wavelet as well as some other frequency space feature explorations in my future work in this direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
